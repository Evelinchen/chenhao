###TF-IDF算法  
===
<br/>
是一种统计加权技术，用来评估一个词对于一个文件或一个语料库中的其中一份文件的重要程度。
<br/>
字词的重要性随着它在文件中出现的次数正相关，但随着它在语料库中出现的频率成反比下降
<br/>
TF：指给定词语在该文件中出现的次数，这个数字通常回被归一化
<br/>
IDF：是一个词语普遍重要性度量，可以由总文件数除以包含该词语的文件数，在把结果取对数
<br/>

###命名实体识别（NER）
===
<br/>
其主要任务是将诸如Guido van Rossum，Microsoft，London等的命名实体分类为人员，组织，地点，时间，日期等预定类别。许多NER系统已经创建，其中最好系统采用的是神经网络。

###深度学习中文分词
===
需要考虑性能、可维护性、词库更新、多粒度<br/>
一般都是基于规则：<br/>
  1.基于最大正向/反向、双向
  2.规则中柔和一定的统计规律，会采用动态规划计算最大的概率路径的分词


bias/varience
---


中心极限定理和大数定律的区别
---
两个都是用来描述（i.i.d）的随机变量的渐进表现，区别在于他们描述的是在不同收敛速率下的表现，大数定律的前提条件弱一些：E(|x|)一阶原点矩存在，中心极限定理需要二阶原点矩存在。


**大数定律**：n越来越大，如果把这n个独立同分布的数加起来除以n得到的这个样本均值（也是一个随机变量），它会依概率收敛到真实值u,但是它的分布是什么样是不知道的。<br/>
**中心极限定理**：n越来越大，这n个样本的均值会趋近于正态分布，并且这个正态分布以u为均值，sigma^2/n为方差。<br/>
综上所述，这两个定律都是在说样本均值性质。随着n增大，大数定律说样本均值几乎必然等于均值。中心极限定律说，他越来越趋近于正态分布。并且这个正态分布的方差越来越小。

直观上来讲，想到大数定律的时候，你脑海里浮现的应该是一个样本，而想到中心极限定理的时候脑海里应该浮现出很多个样本


关于训练加速和走出拐点
---
**mini-batch：**对于数量很大的data set(比方500万)  
batch方法更新一次W就需要遍历整个数据集，mini-batch把500万分割成5ooo个batch，每个batch1000个样本，这样每更新一次只需要计算1000个样本，完成5000个batch上的更新即完成一个epoch。  
